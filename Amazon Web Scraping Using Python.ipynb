e{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc9b9564",
   "metadata": {},
   "source": [
    "# Amazon Web Scraping Using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a820875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dd2e4879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "import smtplib\n",
    "from selenium import webdriver #To scrape a webpage that relies on JavaScript to load dynamic content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3546e824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a csv file\n",
    "import csv\n",
    "\n",
    "header = ['Title', 'Price', 'Reviews', 'Date']\n",
    "\n",
    "# Let's name our file\n",
    "with open('AmazonWebScraperData.csv', 'w', newline='', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b0d0ae76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Title, Price, Reviews, Date]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'/Users/username/AmazonWebScraperData.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3e3d82a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to check the price\n",
    "def check_price():\n",
    "    url = 'https://www.amazon.com/Purina-Pro-Plan-Shredded-Chicken/dp/B001VIWHMY/ref=sr_1_1_sspa?c=ts&dib=eyJ2IjoiMSJ9.gTlB5Nw7kn5_xISkmyyvDNEcy5lBTgMwVve74BV4FSuk92cRMtaoje1zlHB2Pv4ttxluzKLSHb-IBu_4M6tEKQ.g6yhi4W91euRABnH1G6S55Fr4Vau_9AfY50wHwoNoSA&dib_tag=se&keywords=Dog%2BFood&qid=1704995498&rdc=1&s=pet-supplies&sr=1-1-spons&ts_id=2975359011&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&th=1'\n",
    "\n",
    "    # Use Selenium to load the page with JavaScript\n",
    "    driver = webdriver.Chrome()  # You need to have the ChromeDriver installed and in your PATH\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the page to load (you might need to adjust the sleep time)\n",
    "    time.sleep(10)\n",
    "\n",
    "    # Get the page source after JavaScript has loaded\n",
    "    page_source = driver.page_source\n",
    "\n",
    "    # Close the browser window\n",
    "    driver.quit()\n",
    "\n",
    "    # Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    soup_pretty = BeautifulSoup(soup.prettify(), 'html.parser')\n",
    "\n",
    "    # Let's extract the product title, price, and reviews\n",
    "    title = soup_pretty.find(id='productTitle').get_text()\n",
    "\n",
    "    price_element = soup_pretty.select_one('.a-section.a-spacing-none.aok-align-center .a-price.a-text-price.a-size-medium.apexPriceToPay .a-offscreen')\n",
    "    price = price_element.get_text()\n",
    "    \n",
    "    reviews_element = soup_pretty.find(class_='a-icon a-icon-star a-star-4-5 cm-cr-review-stars-spacing-big')\n",
    "    reviews = reviews_element.find('span', class_='a-icon-alt').get_text()\n",
    "\n",
    "    # Let's strip the whitespaces of the outputs and then we'll print it so we can verify it worked\n",
    "    price = float(price.strip()[1:])\n",
    "    formatted_price = \"{:.2f}\".format(float(price))\n",
    "    title = title.strip()\n",
    "    reviews = reviews.strip()\n",
    "    \n",
    "    today = datetime.date.today()\n",
    "    \n",
    "    # Let's create a csv file\n",
    "    import csv\n",
    "\n",
    "    header = ['Title', 'Price', 'Reviews', 'Date']\n",
    "    data = [title, formatted_price, reviews, today]\n",
    "    \n",
    "    # We are now appending data to the csv\n",
    "    with open('AmazonWebScraperData.csv', 'a+', newline='', encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e6473ff2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m check_price()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# timer runs every day -> 86,400 seconds\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m86400\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# We're going to put our function on a timer to run every day\n",
    "while(True):\n",
    "    check_price()\n",
    "    # timer runs every day -> 86,400 seconds\n",
    "    time.sleep(86400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3fe9fe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title   Price  \\\n",
      "0  Purina Pro Plan High Protein Dog Food With Pro...   47.10   \n",
      "1  Purina Pro Plan High Protein Dog Food With Pro...    47.1   \n",
      "2  Purina Pro Plan High Protein Dog Food With Pro...   47.10   \n",
      "3  Purina Pro Plan High Protein Dog Food With Pro...  $47.10   \n",
      "4  Purina Pro Plan High Protein Dog Food With Pro...   47.10   \n",
      "\n",
      "              Reviews        Date  \n",
      "0  4.7 out of 5 stars  2024-01-11  \n",
      "1  4.7 out of 5 stars  2024-01-11  \n",
      "2  4.7 out of 5 stars  2024-01-11  \n",
      "3  4.7 out of 5 stars  2024-01-11  \n",
      "4  4.7 out of 5 stars  2024-01-11  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'/Users/username/AmazonWebScraperData.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1439c3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
